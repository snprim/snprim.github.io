<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"  
  "http://www.w3.org/TR/html4/loose.dtd">  
<html > 
<head><title>ST793 Project: A Blogpost on &#8220;Doubly Enhanced EM Algorithm for Model-Based Tensor
Clustering&#8221; by Mai et al</title> 
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1"> 
<meta name="generator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<meta name="originator" content="TeX4ht (https://tug.org/tex4ht/)"> 
<!-- html --> 
<meta name="src" content="blog.tex"> 
<link rel="stylesheet" type="text/css" href="blog.css"> 
</head><body 
>
   <div class="maketitle">
                                                                                      
                                                                                      
                                                                                      
                                                                                      

<h2 class="titleHead">ST793 Project: A Blogpost on &#8220;Doubly Enhanced EM Algorithm
for Model-Based Tensor Clustering&#8221; by Mai et al</h2>
 <div class="author" ><span 
class="cmr-12">Ayumi Mutoh, Jisu Oh, Shih-Ni Prim</span></div><br />
<div class="date" ><span 
class="cmr-12">December 2, 2023</span></div>
   </div>
   <h3 class="sectionHead"><span class="titlemark">1   </span> <a 
 id="x1-10001"></a>Introduction</h3>
<!--l. 29--><p class="noindent" >In recent decades, tensor data have gained popularity in modern science, their high-dimensional
structures often pose challenges for statistical analysis, specifically in model-based clustering.
Model-based clustering is a statistical approach to data clustering, where observed data is considered
to have been created from a finite combination of component models, such as the Gaussian mixture
model (GMM). Since the formalization of the expected-maximization (EM) algorithm by <span 
class="cmbx-10x-x-109">?</span>, the EM
algorithm has been widely employed in the majority of model-based clustering applications. While the
GMMs can be readily extended to higher-order tensors using the standard EM algorithm, their
performance can be further enhanced by integrating the DEEM algorithm, as proposed by <span 
class="cmbx-10x-x-109">?</span>. Mai et
al. consider a tensor normal mixture model (TNMM) that incorporates tensor correlation
structure and variable selection for clustering and parameter estimation. They developed the
DEEM algorithm which enables DEEM to excel in high-dimensional tensor data analysis.
Similar to the EM algorithm, DEEM carries out an enhanced E-step and an enhanced
M-step.
<!--l. 31--><p class="indent" >   In this blogpost, we first introduce the DEEM methods with intermediate steps for the theoretical
explanation. The objective is to break down the steps, making the derivation more accessible for our
readers to follow. Subsequently, we will conduct a simulation study to evaluate the performance of
DEEM.
<!--l. 35--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">2   </span> <a 
 id="x1-20002"></a>Theoretical Derivation</h3>
                                                                                      
                                                                                      
<!--l. 36--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">2.1   </span> <a 
 id="x1-30002.1"></a>EM Algorithm</h4>
<!--l. 37--><p class="noindent" >Before delving into DEEM, we would like to review the EM algorithm and its functioning in
clustering.
<!--l. 39--><p class="indent" >   As we have learned in class, the EM algorithm is an iterative approach that cycles between two
steps for maximum likelihood estimation in the presence of latent variables. The observed data Y is
incomplete and data Z is missing. The first step is to write down the joint likelihood, <span 
class="cmmi-10x-x-109">L</span><sub><span 
class="cmmi-8">c</span></sub>(<span 
class="cmmi-10x-x-109">&#x03B8;</span><span 
class="cmsy-10x-x-109">|</span><span 
class="cmmi-10x-x-109">Y,Z</span>), of
the &#8220;complete&#8221; data (<span 
class="cmmi-10x-x-109">Y,Z</span>). The &#8220;E&#8221; step of the EM algorithm is to compute the conditional
expectation of log-likelihood, log<span 
class="cmmi-10x-x-109">L</span><sub><span 
class="cmmi-8">c</span></sub>(<span 
class="cmmi-10x-x-109">&#x03B8;</span><span 
class="cmsy-10x-x-109">|</span><span 
class="cmmi-10x-x-109">Y,Z</span>), given Y assuming the true parameter value is
<span 
class="cmmi-10x-x-109">&#x03B8;</span><sup><span 
class="cmr-8">(</span><span 
class="cmmi-8">&#x03BD;</span><span 
class="cmr-8">)</span></sup>
   <div class="math-display" >
<img 
src="blog0x.png" alt="Q (&#x03B8;,&#x03B8;(&#x03BD;),Y ) = E &#x03B8;(&#x03BD;)(logLc (&#x03B8;|Y,Z )|Y ).
" class="math-display" ></div>
<!--l. 43--><p class="indent" >   In the &#8220;M&#8221; step, we maximize <span 
class="cmmi-10x-x-109">Q</span>(<span 
class="cmmi-10x-x-109">&#x03B8;,&#x03B8;</span><sup><span 
class="cmr-8">(</span><span 
class="cmmi-8">&#x03BD;</span><span 
class="cmr-8">)</span></sup><span 
class="cmmi-10x-x-109">,Y </span>) with respect to <span 
class="cmmi-10x-x-109">&#x03B8; </span>with <span 
class="cmmi-10x-x-109">&#x03B8;</span><sup><span 
class="cmr-8">(</span><span 
class="cmmi-8">&#x03BD;</span><span 
class="cmr-8">)</span></sup> fixed.
<!--l. 51--><p class="indent" >   The EM algorithm is well-known for use in unsupervised learning problems such as clustering with
a mixture model. The process goes as follows:
     <ol  class="enumerate1" >
<li 
  class="enumerate" id="x1-3002x1">
     <!--l. 53--><p class="noindent" >Identify the number of clusters.
     </li>
<li 
  class="enumerate" id="x1-3004x2">
     <!--l. 54--><p class="noindent" >Define each cluster by generating a Gaussian model.
     </li>
<li 
  class="enumerate" id="x1-3006x3">
                                                                                      
                                                                                      <!--l. 55--><p class="noindent" >For every observation, calculate the probability that it belongs to each cluster (Ex.
     observation 12 has 40% probability of belonging to Cluster A and 60% probability of
     belonging to Cluster B.)
     </li>
<li 
  class="enumerate" id="x1-3008x4">
     <!--l. 56--><p class="noindent" >Using the above probabilities, recalculate the Gaussian models.
     </li>
<li 
  class="enumerate" id="x1-3010x5">
     <!--l. 57--><p class="noindent" >Repeat until observations &#8220;converge&#8221; on their assignments.</li></ol>
<!--l. 60--><p class="indent" >   Let&#8217;s consider a simple example. Suppose we have data <span 
class="cmmi-10x-x-109">X</span><sub><span 
class="cmmi-8">i</span></sub> as shown in Figure <a 
href="#x1-3011r1">1<!--tex4ht:ref: fig:clustering1 --></a>, which comes
from two distinct classes. We use this data to build a Gaussian model for each class. Since we don&#8217;t
know which class each observation belongs to, there is no straightforward way to construct two
Gaussian models to partition the data. Therefore, we begin with a random guess of our Gaussian
model parameters: <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmr-8">1</span></sub><span 
class="cmmi-10x-x-109">,&#x03C3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmr-8">2</span></sup><span 
class="cmmi-10x-x-109">,&#x03BC;</span><sub><span 
class="cmr-8">2</span></sub><span 
class="cmmi-10x-x-109">,&#x03C3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmr-8">2</span></sup>.
<!--l. 62--><p class="indent" >   We have &#8216;missing&#8217; data points <span 
class="cmmi-10x-x-109">X</span><sub><span 
class="cmmi-8">i</span></sub> that we believe belong to either of the two distributions. After
initializing two random Gaussian models, we compute the likelihood of each observation, <span 
class="cmmi-10x-x-109">X</span><sub><span 
class="cmmi-8">i</span></sub>, being
expressed in both of the Gaussian models. The next is the E-step, where we compute the probability
that each <span 
class="cmmi-10x-x-109">X</span><sub><span 
class="cmmi-8">i</span></sub> can belong to any of two distributions. Now we have a probability of belonging to either
distribution for each point.
<!--l. 64--><p class="indent" >   In the M-step, we update the parameters, <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmr-8">1</span></sub><span 
class="cmmi-10x-x-109">,&#x03C3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmr-8">2</span></sup><span 
class="cmmi-10x-x-109">,&#x03BC;</span><sub><span 
class="cmr-8">2</span></sub><span 
class="cmmi-10x-x-109">,&#x03C3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmr-8">2</span></sup>, of the model to their most likely values.
For the new <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmr-8">1</span></sub>, we take a weighted average of all the points, weighted by the probability that they
belong to the first distribution. Denoting <span 
class="cmmi-10x-x-109">p</span><sub><span 
class="cmmi-8">i</span></sub> is the probability that <span 
class="cmmi-10x-x-109">X</span><sub><span 
class="cmmi-8">i</span></sub> belongs to the first
distribution.
   <div class="math-display" >
<img 
src="blog1x.png" alt="     p1X1-+-p2X2-+-&#x22C5;&#x22C5;&#x22C5;+-pnXn--
&#x03BC;1 =     p1 + p2 + &#x22C5;&#x22C5;&#x22C5;+ pn
" class="math-display" ></div>
<!--l. 66--><p class="indent" >   The new <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmr-8">2</span></sup> can be updated similarly.
                                                                                      
                                                                                      
   <div class="math-display" >
<img 
src="blog2x.png" alt=" 2   p1(X1---&#x03BC;1)2-+-p2(X2---&#x03BC;1)2 +-&#x22C5;&#x22C5;&#x22C5;+-pn(Xn---&#x03BC;1-)2
&#x03C3;1 =                p1 + p2 + &#x22C5;&#x22C5;&#x22C5;+ pn
" class="math-display" ></div>
<!--l. 68--><p class="indent" >   We repeat this process for <span 
class="cmmi-10x-x-109">&#x03BC;</span><sub><span 
class="cmr-8">2</span></sub> and <span 
class="cmmi-10x-x-109">&#x03C3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmr-8">2</span></sup> and update our distributions. We iterate through the E-step
and M-step until convergence, obtaining two clusters as shown in Figure <a 
href="#x1-3012r2">2<!--tex4ht:ref: fig:clustering2 --></a>.
<!--l. 73--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                      
                                                                                      
                                                                                      
                                                                                      <!--l. 75--><p class="noindent" ><img 
src="nocolor.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-3011r1"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Figure&#x00A0;1: </span><span  
class="content">Mixture of two Gaussian Distributions                                          </span></div><!--tex4ht:label?: x1-3011r1 -->
                                                                                      
                                                                                      <!--l. 78--><p class="indent" ></div><hr class="endfigure">
<!--l. 81--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                      
                                                                                      
                                                                                      
                                                                                      <!--l. 83--><p class="noindent" ><img 
src="clustering.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-3012r2"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Figure&#x00A0;2: </span><span  
class="content">Clusters Found by EM algorithm                                              </span></div><!--tex4ht:label?: x1-3012r2 -->
                                                                                      
                                                                                      <!--l. 86--><p class="indent" ></div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">2.2   </span> <a 
 id="x1-40002.2"></a>Tensor</h4>
<!--l. 91--><p class="noindent" >While the term &#8220;tensor&#8221; might sound unfamiliar to some, tensors are simply multi-way arrays. Data is
often structured as matrices, and they are in fact second-order tensors. When we use the term
&#8220;tensor,&#8221; we usually mean tensors of third-order and higher. You can think of a third-order tensor as
a cube. There are then three dimensions from which to look at the tensor. These three dimensions are
called &#8220;modes.&#8221; If you are interested in knowing more about tensors, a very popular and
highly cited paper by <span 
class="cmbx-10x-x-109">? </span>has lots of great details. So check it out! A figure from this paper is
included in our Figure <a 
href="#x1-4001r3">3<!--tex4ht:ref: fig:tensor --></a> to give you an idea of the different ways to look at a tensor. For
this blogpost, we will focus on the method DEEM by <span 
class="cmbx-10x-x-109">?</span>, so we will not delve into more
details about tensors and will focus on how this method is an upgrade of the classical EM
algorithm.
<!--l. 93--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                      
                                                                                      
                                                                                      
                                                                                      <!--l. 95--><p class="noindent" ><img 
src="tensor.png" alt="PIC"  
width="284" height="284" > <a 
 id="x1-4001r3"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Figure&#x00A0;3: </span><span  
class="content">Dimensions and Terminology of a Tensor (from <span 
class="cmbx-10x-x-109">?</span>)                               </span></div><!--tex4ht:label?: x1-4001r3 -->
                                                                                      
                                                                                      <!--l. 98--><p class="indent" ></div><hr class="endfigure">
   <h4 class="subsectionHead"><span class="titlemark">2.3   </span> <a 
 id="x1-50002.3"></a>Doubly Enhanced EM Algorithm</h4>
<!--l. 102--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">3   </span> <a 
 id="x1-60003"></a>Simulation Study</h3>
<!--l. 104--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.1   </span> <a 
 id="x1-70003.1"></a>Data Generation</h4>
<!--l. 106--><p class="noindent" >For our simulation studies, we follow the framework used in <span 
class="cmbx-10x-x-109">?</span>. For each setting, <span 
class="cmmi-10x-x-109">K </span>denotes the
number of mixture groups, and noise is generated as a <span 
class="cmmi-10x-x-109">M</span><sup><span 
class="cmmi-8">th</span></sup>-order tensor:
   <table 
class="equation"><tr><td>
   <div class="math-display" >
<img 
src="blog3x.png" alt="     &#x2211;K
Xi ~    &#x03C0; *kTN (&#x03C0; *k;&#x03A3; *1,&#x22C5;&#x22C5;&#x22C5; ,&#x03A3;*M ),i = 1,&#x22C5;&#x22C5;&#x22C5; ,n
     k=1
" class="math-display" ><a 
 id="x1-7001r1"></a></div>
   </td><td class="equation-label">(1)</td></tr></table>
<!--l. 109--><p class="nopar" >For <span 
class="cmmi-10x-x-109">K </span><span 
class="cmsy-10x-x-109">- </span>1 mixture groups, the <span 
class="cmbx-10x-x-109">X</span><sub><span 
class="cmmi-8">i</span></sub> is given as a given <span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmmi-8">k</span></sub> plus the noise above. For 1 mixture group,
the values are simply the noise. <span 
class="cmbx-10x-x-109">? </span>designate two types of <span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmmi-8">k</span></sub><sup><span 
class="cmsy-8">*</span></sup>:
   <div class="math-display" >
<img 
src="blog4x.png" alt="     ({                |i- j|
&#x03A9;  =   AR (&#x03C1;) : &#x03C9;ij = &#x03C1;
     ( CS (&#x03C1;) : &#x03C9;  = &#x03C1; + (1- &#x03C1;)1(i = j).
                 ij
                                                                                      
                                                                                      " class="math-display" ></div>
<!--l. 115--><p class="indent" >   For each setting, we generate 100 independent datasets, the same number of replicates as <span 
class="cmbx-10x-x-109">? </span>use,
and present the mean error rate and standard deviation.
<!--l. 117--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.2   </span> <a 
 id="x1-80003.2"></a>Settings</h4>
<!--l. 119--><p class="noindent" >The settings are provided in Table <a 
href="#x1-8001r1">1<!--tex4ht:ref: tab:sim_setting --></a>. Note that, for <span 
class="cmmi-10x-x-109">B</span><sub><span 
class="cmmi-8">k</span></sub><sup><span 
class="cmsy-8">*</span></sup>, the indices not included in the subscript is 0.
In other words, <span 
class="cmmi-10x-x-109">B</span><sub><span 
class="cmmi-8">k</span></sub><sup><span 
class="cmsy-8">*</span></sup> is a sparse tensor. We chose these four settings from the seven settings, because
their settings are increasingly more computationally expensive, and we believe that these four settings
demonstrate the advantage of the DEEM algorithm compared to the classical EM algorithm in terms
of accuracy, as shown in Table <a 
href="#x1-11001r2">2<!--tex4ht:ref: tab:err --></a>.
   <div class="table">
                                                                                      
                                                                                      <!--l. 121--><p class="indent" ><hr class="float"><div class="float" 
>
                                                                                      
                                                                                      
<div class="tabular"> <table id="TBL-2" class="tabular" 
 
><colgroup id="TBL-2-1g"><col 
id="TBL-2-1"></colgroup><colgroup id="TBL-2-2g"><col 
id="TBL-2-2"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-2-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-1-1"  
class="td11"> Model  </td><td  style="white-space:normal; text-align:left;" id="TBL-2-1-2"  
class="td11"> <!--l. 124--><p class="noindent" >Parameters                                                                  </td>
</tr><tr 
class="hline"><td><hr></td><td><hr></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-2-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-2-1"  
class="td11">   M1    
</td><td  style="white-space:normal; text-align:left;" id="TBL-2-2-2"  
class="td11"> <!--l. 126--><p class="noindent" ><span 
class="cmmi-10x-x-109">K </span>= 2<span 
class="cmmi-10x-x-109">,p </span>= 10<span 
class="cmsy-10x-x-109">&#x00D7;</span>10<span 
class="cmsy-10x-x-109">&#x00D7;</span>4<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">CS</span>(0<span 
class="cmmi-10x-x-109">.</span>3)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">AR</span>(0<span 
class="cmmi-10x-x-109">.</span>8)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">3</span></sub><sup><span 
class="cmsy-8">*</span></sup> =
  <span 
class="cmmi-10x-x-109">CS</span>(0<span 
class="cmmi-10x-x-109">.</span>3)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">2</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = 0<span 
class="cmmi-10x-x-109">.</span>5                                                </td>
</tr><tr 
class="hline"><td><hr></td><td><hr></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-2-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-3-1"  
class="td11">   M3    
</td><td  style="white-space:normal; text-align:left;" id="TBL-2-3-2"  
class="td11"> <!--l. 128--><p class="noindent" ><span 
class="cmmi-10x-x-109">K </span>= 3<span 
class="cmmi-10x-x-109">,p </span>= 10<span 
class="cmsy-10x-x-109">&#x00D7;</span>10<span 
class="cmsy-10x-x-109">&#x00D7;</span>4<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">CS</span>(0<span 
class="cmmi-10x-x-109">.</span>3)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">AR</span>(0<span 
class="cmmi-10x-x-109">.</span>8)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">3</span></sub><sup><span 
class="cmsy-8">*</span></sup> =
  <span 
class="cmmi-10x-x-109">CS</span>(0<span 
class="cmmi-10x-x-109">.</span>5)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">2</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = 0<span 
class="cmmi-10x-x-109">.</span>5<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">3</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmsy-10x-x-109">-</span>0<span 
class="cmmi-10x-x-109">.</span>5                      </td>
</tr><tr 
class="hline"><td><hr></td><td><hr></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-2-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-4-1"  
class="td11">   M4    
</td><td  style="white-space:normal; text-align:left;" id="TBL-2-4-2"  
class="td11"> <!--l. 130--><p class="noindent" ><span 
class="cmmi-10x-x-109">K </span>= 4<span 
class="cmmi-10x-x-109">,p </span>= 10 <span 
class="cmsy-10x-x-109">&#x00D7; </span>10 <span 
class="cmsy-10x-x-109">&#x00D7; </span>4<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmbx-10x-x-109">I</span><sub><span 
class="cmr-8">10</span></sub><span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">AR</span>(0<span 
class="cmmi-10x-x-109">.</span>8)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">3</span></sub><sup><span 
class="cmsy-8">*</span></sup> =
  <span 
class="cmbx-10x-x-109">I</span><sub><span 
class="cmr-8">4</span></sub><span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">2</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = 0<span 
class="cmmi-10x-x-109">.</span>8<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">3</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmsy-10x-x-109">-</span>0<span 
class="cmmi-10x-x-109">.</span>8                              </td>
</tr><tr 
class="hline"><td><hr></td><td><hr></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-2-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-2-5-1"  
class="td11">   M5    
</td><td  style="white-space:normal; text-align:left;" id="TBL-2-5-2"  
class="td11"> <!--l. 132--><p class="noindent" ><span 
class="cmmi-10x-x-109">K </span>= 6<span 
class="cmmi-10x-x-109">,p </span>= 10<span 
class="cmsy-10x-x-109">&#x00D7;</span>10<span 
class="cmsy-10x-x-109">&#x00D7;</span>4<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">1</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">AR</span>(0<span 
class="cmmi-10x-x-109">.</span>9)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">2</span></sub><sup><span 
class="cmsy-8">*</span></sup> = <span 
class="cmmi-10x-x-109">CS</span>(0<span 
class="cmmi-10x-x-109">.</span>6)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">&#x03A3;</span><sub><span 
class="cmr-8">3</span></sub><sup><span 
class="cmsy-8">*</span></sup> =
  <span 
class="cmmi-10x-x-109">AR</span>(0<span 
class="cmmi-10x-x-109">.</span>9)<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">2</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> =  0<span 
class="cmmi-10x-x-109">.</span>6<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">3</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> =  1<span 
class="cmmi-10x-x-109">.</span>2<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">4</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> =
  1<span 
class="cmmi-10x-x-109">.</span>8<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">5</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = 2<span 
class="cmmi-10x-x-109">.</span>4<span 
class="cmmi-10x-x-109">,</span><span 
class="cmbx-10x-x-109">B</span><sub><span 
class="cmr-8">6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">[1:6</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1</span><span 
class="cmmi-8">,</span><span 
class="cmr-8">1]</span></sub><sup><span 
class="cmsy-8">*</span></sup> = 3                                  </td>
</tr></table>                                                                                      </div>
<a 
 id="x1-8001r1"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Table&#x00A0;1: </span><span  
class="content">Simulation settings
</span></div><!--tex4ht:label?: x1-8001r1 -->
                                                                                      
                                                                                      </div><hr class="endfloat" />
   </div>
   <h4 class="subsectionHead"><span class="titlemark">3.3   </span> <a 
 id="x1-90003.3"></a>Metrics</h4>
<!--l. 140--><p class="noindent" >Note that it is as straightforward to calculate the mean error rate for a clustering problem than it is
for a classification problem. Both methods return labels for the groups; however, the group labels do
not matter. For example, if there are five observations and if their true group labels are (1<span 
class="cmmi-10x-x-109">,</span>1<span 
class="cmmi-10x-x-109">,</span>2<span 
class="cmmi-10x-x-109">,</span>2<span 
class="cmmi-10x-x-109">,</span>2)
and the methods return (2<span 
class="cmmi-10x-x-109">,</span>2<span 
class="cmmi-10x-x-109">,</span>1<span 
class="cmmi-10x-x-109">,</span>1<span 
class="cmmi-10x-x-109">,</span>1), the error rate should be 0. In the paper, the authors explain that
mean clustering error rate is calculated by:
   <div class="math-display" >
<img 
src="blog5x.png" alt="      &#x2211;n        &#x220F;                                   &#x220F;
min 1-   1(Y&#x02C6;i &#x2044;=   (Yi)) over all possible permutations  : {1,&#x22C5;&#x22C5;&#x22C5; ,} &#x21A6;&#x2192; {1,&#x22C5;&#x22C5;&#x22C5; ,K }
 &#x220F;  n i=1
" class="math-display" ></div>
<!--l. 142--><p class="indent" >   We thus created a function to permute the true labels, compare the estimated labels and the true
labels, and return the lowest error rate.
<!--l. 144--><p class="indent" >   To compare the speed of the two methods, we also record the computation time. Table <a 
href="#x1-11002r3">3<!--tex4ht:ref: tab:time --></a> provides
the mean computation time and standard error (in parentheses) for each setting.
<!--l. 146--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.4   </span> <a 
 id="x1-100003.4"></a>External R Packages and Functions</h4>
<!--l. 148--><p class="noindent" >For the DEEM algorithm, we use the function DEEM; for the standard EM algorithm, we use the
function TGMM. Both functions are from the R package TensorClustering. We use the Trnorm
function from the R package Tlasso to generate tensor noise with designated covariance matrices. We
use the permutations function in the gtools package to permute true labels. In short, be sure to install
the three R packages: TensorClustering, Tlasso, and gtools if you would like to reproduce our
simulation.
                                                                                      
                                                                                      <!--l. 151--><p class="noindent" >
   <h4 class="subsectionHead"><span class="titlemark">3.5   </span> <a 
 id="x1-110003.5"></a>Simulation result</h4>
<!--l. 153--><p class="noindent" >The error rates and computation time are shown in Tables <a 
href="#x1-11001r2">2<!--tex4ht:ref: tab:err --></a> and <a 
href="#x1-11002r3">3<!--tex4ht:ref: tab:time --></a>. It is clear that DEEM has lower
mean error rates in all four settings. The computation time tells a different story, however. As seen in
Table <a 
href="#x1-11002r3">3<!--tex4ht:ref: tab:time --></a>, DEEM is not always the winner in terms of time. As the setting becomes more complicated
and estimating the clusters becomes more challenging, it takes longer for DEEM to converge. In fact,
judging from the amount of time it took to run the setting M5, it is possible that DEEM reached the
maximum iterations.
   <div class="table">
                                                                                      
                                                                                      <!--l. 155--><p class="indent" ><hr class="float"><div class="float" 
>
                                                                                      
                                                                                      
<div class="tabular"> <table id="TBL-3" class="tabular" 
 
><colgroup id="TBL-3-1g"><col 
id="TBL-3-1"></colgroup><colgroup id="TBL-3-2g"><col 
id="TBL-3-2"><col 
id="TBL-3-3"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-3-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-1"  
class="td11"> Model  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-2"  
class="td11">   DEEM    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-1-3"  
class="td11">    EM      </td>
</tr><tr 
class="hline"><td><hr></td><td><hr></td><td><hr></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-3-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-3-2-1"  
class="td11">   M1    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-2-2"  
class="td11"> 0.41 (0.05)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-2-3"  
class="td11"> 0.45 (0.03)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-1"  
class="td11">   M3    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-2"  
class="td11"> 0.46 (0.09)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-3-3"  
class="td11"> 0.56 (0.05)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-1"  
class="td11">   M4    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-2"  
class="td11"> 0.35 (0.03)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-4-3"  
class="td11"> 0.57 (0.06)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-3-5-1"  
class="td11">   M5    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-5-2"  
class="td11"> 0.31 (0.11)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-3-5-3"  
class="td11"> 0.43 (0.06)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-3-6-"><td  style="white-space:nowrap; text-align:center;" id="TBL-3-6-1"  
class="td11">        </td></tr></table>                                                                           </div>
<a 
 id="x1-11001r2"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Table&#x00A0;2: </span><span  
class="content">Error Rates from 100 Replicates
</span></div><!--tex4ht:label?: x1-11001r2 -->
                                                                                      
                                                                                      </div><hr class="endfloat" />
   </div>
   <div class="table">
                                                                                      
                                                                                      <!--l. 169--><p class="indent" ><hr class="float"><div class="float" 
>
                                                                                      
                                                                                      
<div class="tabular"> <table id="TBL-4" class="tabular" 
 
><colgroup id="TBL-4-1g"><col 
id="TBL-4-1"></colgroup><colgroup id="TBL-4-2g"><col 
id="TBL-4-2"><col 
id="TBL-4-3"></colgroup><tr  
 style="vertical-align:baseline;" id="TBL-4-1-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-1"  
class="td11"> Model  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-2"  
class="td11">    DEEM       </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-1-3"  
class="td11">    EM       </td>
</tr><tr 
class="hline"><td><hr></td><td><hr></td><td><hr></td></tr><tr  
 style="vertical-align:baseline;" id="TBL-4-2-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-1"  
class="td11">   M1    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-2"  
class="td11">   0.72 (0.45)     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-2-3"  
class="td11">  0.93 (0.39)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-3-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-1"  
class="td11">   M3    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-2"  
class="td11">  13.95 (7.78)    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-3-3"  
class="td11">  7.74 (3.99)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-4-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-1"  
class="td11">   M4    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-2"  
class="td11">   15.8 (0.81)     </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-4-3"  
class="td11">  21.9 (9.68)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-5-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-1"  
class="td11">   M5    </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-2"  
class="td11"> 332.96 (124.38)  </td><td  style="white-space:nowrap; text-align:center;" id="TBL-4-5-3"  
class="td11"> 14.66 (5.88)  </td>
</tr><tr  
 style="vertical-align:baseline;" id="TBL-4-6-"><td  style="white-space:nowrap; text-align:center;" id="TBL-4-6-1"  
class="td11">        </td></tr></table>                                                                           </div>
<a 
 id="x1-11002r3"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Table&#x00A0;3: </span><span  
class="content">Computation Time (seconds) from 100 Replicates
</span></div><!--tex4ht:label?: x1-11002r3 -->
                                                                                      
                                                                                      </div><hr class="endfloat" />
   </div>
<!--l. 183--><p class="indent" >   Next we transform the values in the tables into figures, which sometimes tell clearer pictures. As
shown in Figure <a 
href="#x1-11003r4">4<!--tex4ht:ref: fig:err --></a>, DEEM always has lower mean error rates. However, as the model becomes
complicated, DEEM&#8217;s error rates become more varied, even though the mean rate is still lower.
In Figure <a 
href="#x1-11004r5">5<!--tex4ht:ref: fig:time --></a>, the story seems more complicated. (Note that we cannot make the y-axis
all the same for the four plots, because the computation time for DEEM for M5 is so
long, which would make some of the boxes very small and not informative.) For the two
settings M1 and M4, DEEM has lower computation time. For M3, the computation time
for DEEM is much more varied, and EM has overall shorter computation time. For M5,
DEEM has very long computation time; in fact, the 100 replicates took almost 10 hours
to run. It is unclear if the reduction in error rate is worht the much longer computation
time.
<!--l. 185--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                      
                                                                                      
                                                                                      
                                                                                      <!--l. 187--><p class="noindent" ><img 
src="sim_error.png" alt="PIC"  
width="455" height="455" > <a 
 id="x1-11003r4"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Figure&#x00A0;4: </span><span  
class="content">Boxplots of Mean Error Rates from 100 Replicates                              </span></div><!--tex4ht:label?: x1-11003r4 -->
                                                                                      
                                                                                      <!--l. 190--><p class="indent" ></div><hr class="endfigure">
<!--l. 192--><p class="indent" >   <hr class="figure"><div class="figure" 
>
                                                                                      
                                                                                      
                                                                                      
                                                                                      <!--l. 194--><p class="noindent" ><img 
src="sim_time.png" alt="PIC"  
width="455" height="455" > <a 
 id="x1-11004r5"></a>
<br />                                                                                      <div class="caption" 
><span class="id">
Figure&#x00A0;5: </span><span  
class="content">Boxplots of Mean Computation Time (in seconds) from 100 Replicates            </span></div><!--tex4ht:label?: x1-11004r5 -->
                                                                                      
                                                                                      <!--l. 197--><p class="indent" ></div><hr class="endfigure">
   <h3 class="sectionHead"><span class="titlemark">4   </span> <a 
 id="x1-120004"></a>Discussion</h3>
<!--l. 204--><p class="noindent" >In this blogpost, we review a new method proposed by <span 
class="cmbx-10x-x-109">?</span>, which is essentially an upgraded version of
the classical EM algorithm. This new method, DEEM, tend to have lower error rates on tensor data.
However, the running time could be prohibitive.
<!--l. 206--><p class="noindent" >
   <h3 class="sectionHead"><span class="titlemark">5   </span> <a 
 id="x1-130005"></a>Conclusion</h3>
<!--l. 208--><p class="noindent" >[to be added]
    
</body></html> 

                                                                                      


